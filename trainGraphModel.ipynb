{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vdMY3DQID7q",
        "outputId": "124f8f53-e690-4c37-efbb-9703e085dd00"
      },
      "outputs": [],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "72SKdkyCIFmE",
        "outputId": "6ba05340-9e01-405f-be98-c550f8344ed2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINEConv,global_max_pool,global_add_pool\n",
        "from torch_geometric.nn.norm import BatchNorm\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "\n",
        "indexFullSet = \"INDEX_general_PL_data.2020\" #set to paths to your index files from PDBbind database\n",
        "indexRefinedSet = \"INDEX_refined_data.2020\"\n",
        "indexCoreSet = \"CoreSet.dat\"\n",
        "\n",
        "dataDir = \"\" # change to path containing graphs with names in the format {pdbID}_graph.pt\n",
        "modelPath = \"graphModel.pt\" # path where the model is saved\n",
        "pdbInfoPath = \"\"\n",
        "kinaseFilter = False # change to True for training without kinases in the training data\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "random_seed = 46\n",
        "random.seed(random_seed)\n",
        "\n",
        "\n",
        "\n",
        "def parseIndexFile(indexFilePath):\n",
        "    with open(indexFilePath, \"r\") as index_file:\n",
        "            pdbIDs = []\n",
        "            logKvalues = {}\n",
        "            for line in index_file:\n",
        "                if not line.startswith('#') and line.split()[4].startswith((\"Kd=\",\"Ki=\")): #remove \"line.split()[4].startswith((\"Kd=\",\"Ki=\"))\" to train on filtered general set\n",
        "                    pdbIDs.append(str(line.split()[0]))\n",
        "                    logKvalues[str(line.split()[0])] = float(line.split()[3])\n",
        "    return pdbIDs, logKvalues\n",
        "\n",
        "refinedIndex,logK = parseIndexFile(indexRefinedSet)\n",
        "coreIndex,logKcore = parseIndexFile(indexCoreSet)\n",
        "fullIndex,logKFull = parseIndexFile(indexFullSet)\n",
        "graphData = []\n",
        "logKvalues = []\n",
        "\n",
        "def filterKinases(PDBInfo):\n",
        "  kinases = []\n",
        "  with open(PDBInfo) as file:\n",
        "    for line in file.readlines():\n",
        "      pdbID = line.split(\"\\t\")[0]\n",
        "      pdbinfo = line.split(\"\\t\")[1]\n",
        "      if \"kinase\" in pdbinfo.lower() and pdbID not in kinases:\n",
        "        kinases.append(pdbID)\n",
        "  return kinases\n",
        "\n",
        "\n",
        "class PDBData(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_list, transform=None):\n",
        "        self.data_list = data_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data_list[index]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "\n",
        "class GINENet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GINENet, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        dim = 64\n",
        "        self.atomicNumEmb = nn.Embedding(10,5)\n",
        "        self.formalChargeEmb = nn.Embedding(12,6)\n",
        "        self.aromaticEmb = nn.Embedding(2,1)\n",
        "        self.valenceEmb = nn.Embedding(9,4)\n",
        "        self.hybridizationEmb = nn.Embedding(6,3)\n",
        "        self.chiralityEmb = nn.Embedding(6,3)\n",
        "        self.numHEmb = nn.Embedding(10,5)\n",
        "        self.degreeEmb = nn.Embedding(12,6)\n",
        "        self.typeEmb = nn.Embedding(2,1)\n",
        "        self.residueEmb = nn.Embedding(31, 14)\n",
        "\n",
        "        self.bondTypeEmb = nn.Embedding(7,3)\n",
        "        self.bondDirEmb = nn.Embedding(5,2)\n",
        "        self.stereoEmb = nn.Embedding(6,3)\n",
        "        self.inRingEmb = nn.Embedding(2,1)\n",
        "        self.innerEmb = nn.Embedding(2,1)\n",
        "\n",
        "        self.conv1 = GINEConv(Sequential(Linear(49, dim), BatchNorm(dim), ReLU(),\n",
        "                                         Linear(dim, dim), ReLU()),\n",
        "                                         edge_dim = 11)\n",
        "\n",
        "        self.conv2 = GINEConv(Sequential(Linear(dim, dim), BatchNorm(dim), ReLU(),\n",
        "                                         Linear(dim, dim), ReLU()),\n",
        "                                         edge_dim = 11)\n",
        "\n",
        "        self.norm1 = BatchNorm(dim)\n",
        "        self.norm2 = BatchNorm(dim)\n",
        "\n",
        "        l1_size = 512\n",
        "        input_size = 2*dim*2\n",
        "        self.mlp = Sequential(Linear(input_size,l1_size),\n",
        "                                     BatchNorm(l1_size),\n",
        "                                     ReLU(),\n",
        "                                     Linear(l1_size, l1_size),\n",
        "                                     BatchNorm(l1_size),\n",
        "                                     ReLU(),\n",
        "                                     Linear(l1_size, l1_size),\n",
        "                                     BatchNorm(l1_size),\n",
        "                                     ReLU(),\n",
        "                                     Linear(l1_size,1))\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "\n",
        "        atomicNums = self.atomicNumEmb(x[:,0].long())\n",
        "        chirality = self.chiralityEmb(x[:,1].long())\n",
        "        formalCharge = self.formalChargeEmb(x[:,2].long())\n",
        "        hybridizations = self.hybridizationEmb(x[:,4].long())\n",
        "        numHs = self.numHEmb(x[:,5].long())\n",
        "        valences = self.valenceEmb(x[:,5].long())\n",
        "        degrees = self.degreeEmb(x[:,6].long())\n",
        "        aromatics = self.aromaticEmb(x[:,7].long())\n",
        "        types = self.typeEmb(x[:,8].long())\n",
        "        mass = x[:,9].view(-1,1)\n",
        "        residues = self.residueEmb(x[:,10].long())\n",
        "\n",
        "\n",
        "        dists = edge_attr[:,0].view(-1,1)\n",
        "        bondTypes = self.bondTypeEmb(edge_attr[:,1].long())\n",
        "        bondDirs = self.bondDirEmb(edge_attr[:,2].long())\n",
        "        stereo = self.stereoEmb(edge_attr[:,3].long())\n",
        "        inRing = self.inRingEmb(edge_attr[:,4].long())\n",
        "        inner = self.innerEmb(edge_attr[:,5].long())\n",
        "\n",
        "        x = torch.cat((atomicNums,chirality,formalCharge,hybridizations,numHs,valences,degrees,aromatics,types,mass, residues),dim=1)\n",
        "        edge_attr = torch.cat((dists, bondTypes, bondDirs, stereo, inRing, inner), dim=1)\n",
        "        x1 = self.conv1(x, edge_index, edge_attr)\n",
        "        x1 = self.norm1(x1)\n",
        "        x2 = self.conv2(x1, edge_index, edge_attr)\n",
        "        x2 = self.norm2(x2)\n",
        "\n",
        "        x = torch.cat((x1,x2), dim=1)\n",
        "        x = torch.cat((global_add_pool(x,batch),global_max_pool(x,batch)),dim=1)\n",
        "        x  = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "trainData = []\n",
        "testData = []\n",
        "\n",
        "if not kinaseFilter:\n",
        "    for i,pdbID in enumerate(fullIndex):\n",
        "        if not os.path.isfile(f\"{dataDir}/{pdbID}_graph.pt\"):\n",
        "            continue\n",
        "        with open(f\"{dataDir}/{pdbID}_graph.pt\",\"rb\") as file:\n",
        "                graph = torch.load(file)\n",
        "                graph.y = torch.tensor([logKFull[pdbID]])\n",
        "                graph.y = graph.y.unsqueeze(1)\n",
        "                if pdbID in coreIndex:\n",
        "                    testData.append(graph)\n",
        "                    continue\n",
        "                elif pdbID in fullIndex: #change to refinedIndex for refined set\n",
        "                    trainData.append(graph)\n",
        "\n",
        "else:\n",
        "    kinases = filterKinases(pdbInfoPath)\n",
        "\n",
        "    for i,pdbID in enumerate(refinedIndex):\n",
        "        if not os.path.isfile(f\"{dataDir}/{pdbID}_graph.pt\"):\n",
        "            continue\n",
        "        with open(f\"{dataDir}/{pdbID}_graph.pt\",\"rb\") as file:\n",
        "                graph = torch.load(file)\n",
        "                graph.y = torch.tensor([logKFull[pdbID]])\n",
        "                graph.y = graph.y.unsqueeze(1)\n",
        "                if pdbID in kinases:\n",
        "                    testData.append(graph)\n",
        "                    continue\n",
        "                elif pdbID in refinedIndex and pdbID not in coreIndex: \n",
        "                    trainData.append(graph)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "random.shuffle(trainData)\n",
        "splitSize = int(len(trainData)/10)\n",
        "validData = trainData[:splitSize]\n",
        "trainData = trainData[splitSize:]\n",
        "\n",
        "\n",
        "\n",
        "trainSet = PDBData(data_list = trainData)\n",
        "validSet = PDBData(data_list = validData)\n",
        "testSet = PDBData(data_list = testData)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = GINENet().to(device)\n",
        "#print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "trainloader = DataLoader(trainSet,batch_size = 64,shuffle=True)\n",
        "testloader = DataLoader(testSet,batch_size=1,shuffle=False)\n",
        "validloader = DataLoader(validSet,batch_size=1,shuffle=False)\n",
        "\n",
        "\n",
        "validValues = [data.y.item() for data in validloader]\n",
        "testValues = [data.y.item() for data in testloader]\n",
        "def train():\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for data in trainloader:\n",
        "         data.to(device)\n",
        "         out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "         loss = F.mse_loss(out.squeeze(), data.y.squeeze(), reduction = 'mean')\n",
        "         running_loss += loss.item()*len(data.y.squeeze())\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "    print(running_loss/len(trainloader.dataset))\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "     predictions = []\n",
        "     all_loss = 0\n",
        "     for data in loader:\n",
        "         data.to(device)\n",
        "         out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "         loss = F.mse_loss(out.squeeze(), data.y.squeeze(),reduction = \"mean\")\n",
        "         all_loss += loss.item()\n",
        "         predictions.append(out)\n",
        "     loss = all_loss / len(loader.dataset)\n",
        "\n",
        "     return predictions,loss\n",
        "\n",
        "print(\"start training\")\n",
        "mse= nn.MSELoss()\n",
        "best_valid = (0,0,np.inf,0,0)\n",
        "for epoch in range(1, 1000):\n",
        "    train()\n",
        "    valid_preds,valid_loss = test(validloader)\n",
        "    test_preds, test_loss = test(testloader)\n",
        "    predictions = [float(t.item()) for t in test_preds]\n",
        "    valid_preds = [float(t.item()) for t in valid_preds]\n",
        "    pearson, pvalue = pearsonr(predictions,testValues)\n",
        "    validpearson, pvalid = pearsonr(valid_preds,validValues)\n",
        "    if round(np.sqrt(valid_loss),3) < best_valid[2]:\n",
        "      best_model_state = copy.deepcopy(model.state_dict())\n",
        "      best_valid = (round(pearson,3), round(np.sqrt(test_loss),3), round(np.sqrt(valid_loss),3),round(validpearson,3), epoch)\n",
        "    print(f\" Epoch: {epoch} pearson: {round(pearson,3)} test loss: {round(np.sqrt(test_loss),3)} valid loss: {round(np.sqrt(valid_loss),3)} best: {best_valid}\")\n",
        "\n",
        "torch.save(best_model_state,modelPath)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
